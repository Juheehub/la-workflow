---
title: "LA Foundations - Badge"
subtitle: "LASER Institute Foundation Learning Badge 1"
author: "ADD YOUR NAME HERE"
date: today 
format:
  html:
    toc: true
    toc-depth: 4
    toc-location: right
theme:
  light: simplex
  dark: cyborg
editor: visual
---

![](img/FLA_Primary_Hx.png){width="30%"}

The final activity for each learning lab provides space to work with data and to reflect on how the concepts and techniques introduced in each lab might apply to your own research.

To earn a badge for each lab, you are required to respond to a set of prompts for two parts:

-   In Part I, you will reflect on your understanding of key concepts and begin to think about potential next steps for your own study.

-   In Part II, you will complete a few R exercises that demonstrates your ability to apply the first phases of the LA workflow and data wrangling techniques introduced in this learning lab.

### Part I: Reflect and Plan

Use the institutional library (e.g. [NCSU Library](https://www.lib.ncsu.edu/#articles)), [Google Scholar](https://scholar.google.com/) or search engine to locate a research article, presentation, or resource that applies learning analytics analysis to an educational context or topic of interest. More specifically, **locate a study that makes use of the Learning Analytics Workflow we learned today.** You are also welcome to select one of your research papers.

1.  Provide an APA citation for your selected study.

    -   

2.  What educational issue, "problem of practice," and/or questions were addressed?

    -   

3.  Briefly describe any steps of the data-intensive research workflow that detailed in your article or presentation.

    -   

4.  What were the key findings or conclusions? What value, if any, might education practitioners find in these results?

    -   

5.  Finally, how, if at at, were educators in your self-selected article involved prior to wrangling and analysis?

    -   

Draft a new research question of guided by the the phases of the Learning Analytics Workflow. Or use one of your current research questions.

1.  What educational issue, "problem of practice," and/or questions is addressed??

    -   

2.  Briefly describe any steps of the data-intensive research workflow that can be detailed in your article or presentation.

3.  How, if at all, will your article touch upon the application(s) of LA to "understand and improve learning and the contexts in which learning occurs?"

    -   

### Part II: Data Product

In our Learning Analytics code-along, we scratched the surface on the number of ways that we can wrangle the data.

Using one of the data sets provided in the data folder, your goal for this lab is to extend the Learning Analytics Workflow from our code-along by preparing and wrangling different data.

*Or alternatively, you may use your own data set to use in the workflow. If you do decide to use your own data set you must include:*

-   *Show two different ways using `select` function with your data, inspect and save as a new object.*

-   *Show one way to use `filter` function with your data, inspect and save as a new object.*

-   *Show one way using `arrange` function with your data, inspect and save as a new object.*

-   *Use the pipe operator to bring it all together.*

Feel free to create a new script in your lab 2 to work through the following problems. Then when satisfied add the code in the code chunks below. Don't forget to run the code to make sure it works.

**Instructions:**

1.  *Add* your name to the document in author.

2.  Set up the first (or, two if using an Introduction) phases of the LA workflow below. I've added the wrangle section for you. You will need to `Prepare` the libraries necessary to wrangle the data.

## Wrangle

3.  In the chunk called `read-data`:Import the sci-online-classes.csv from the data folder and save as a new object called sci_classes. Then inspect your data using a function of your choice.

```{python, read-data}
# Type your code here


# Load the CSV file


# Inspect the DataFrame


```


4.  In the select-1 code chunk: Use the indexing method to select student_id, subject, semester, FinalGradeCEMS. Assign to a new object with a different name.

```{python, select-1}
# Type your code here
# Select specific columns and create a new DataFrame


# Inspect the selected data

```

What do you notice about FinalGradeCEMS?(\*Hint: NAs?)

-   Answer here {possible answer: *I notice NA values indicating missing data. This requires handling either by imputation or removal depending on the analysis requirements.*}

5.  In the code chunk below, handle the missing values in the dataFrame you just created.

```{python}
# Select specific columns and create a new DataFrame
selected_data = sci_classes[['student_id', 'subject', 'semester', 'FinalGradeCEMS']]

# Inspect the selected data for missing values


# Handle missing values in 'FinalGradeCEMS'




# Display the cleaned data


```

6.  In code chunk named `select-2`: Select all columns except subject and section. Assign to a new object with a different name. Inspect your data frame with a different function.

```{python, select-2}
# Type your code here
# Select all columns except 'subject' and 'section'


# Inspect the reduced data

```

7.  In the code chunk named `filter-1`, Filter the sci_classes data frame for students in OcnA courses. Assign to a new object with a different name. Use the head() function to examine your data frame.

```{python, filter-1}
#Type your code here


# Display the first few rows of the filtered data

```

Q: How many rows does the head() function display? *Hint: Check the dimensions of your tibble in the console.*

-   Answer here

{Possible answerr: *The head function displays 5 rows of data*}

8.  In code chunk named `filter-2`, Filter the sci_classes data frame so rows with NA for points earned are removed. Assign to a new object with a different name. Use info() to examine all columns of your data frame.

```{python, filter 2}
# Filter out rows with NA in 'points_earned'


# Inspect the modified DataFrame

```

9.  In the code chunk called `arrange-1`: Arrange sci_classes data by subject then percentage_earned in descending order. Assign to a new object. Use the dtypes function to examine the data type of each column in your data frame.

```{python}
# Type your code here
# Arrange the DataFrame by 'subject' and 'percentage_earned' in descending order


# Inspect the structure of the arranged DataFrame

```

10. Use the pandas library to chain together multiple data manipulation methods on the sci_classes data. Here's what you need to do step by step:

-   Select the columns student_id, subject, semester, and FinalGradeCEMS.
-   Filter the data to include only rows where the subject is 'OcnA'.
-   Arrange the data by FinalGradeCEMS in descending order.
-   Assign the result to a new object called final_data.
-   Examine the contents of final_data using a print statement to display the results.

```{python}
#Type your code here
# Use chaining to select, filter, and arrange data


# Examine the contents of the final data manipulation


```

### Render & Submit

Congratulations, you've completed Foundations Learning Badge 1!

To receive your the Foundations Badge, you will need to render this document and publish via a method designated by your instructor such as: [Quarto Pub](https://quarto.org/docs/publishing/quarto-pub.html), [Posit Cloud](https://posit.cloud/learn/guide#publish-from-cloud), [RPubs](https://rpubs.com) , [GitHub Pages](https://quarto.org/docs/publishing/github-pages.html), or [other methods](https://quarto.org/docs/publishing/other.html). Once you have shared a link to you published document with your instructor and they have reviewed your work, you will be provided a physical or digital version of the badge pictured at the top of this document!

If you have any questions about this badge, or run into any technical issues, don't hesitate to contact your instructor.

![](img/share-link.png){width="80%"}

Once your instructor has checked your link, you will be provided a physical version of the badge below!

*Complete the following steps to submit your work for review by:*

Complete the following steps to knit and publish your work:

1.  First, change the name of the `author:` in the [YAML header](https://bookdown.org/yihui/rmarkdown-cookbook/rmarkdown-anatomy.html#yaml-metadata) at the very top of this document to your name. The YAML header controls the style and feel for knitted document but doesn't actually display in the final output.

2.  Next, click the knit button in the toolbar above to "knit" your R Markdown document to a [HTML](https://bookdown.org/yihui/rmarkdown/html-document.html) file that will be saved in your R Project folder. You should see a formatted webpage appear in your Viewer tab in the lower right pan or in a new browser window. Let's us know if you run into any issues with knitting.

3.  Finally, publish.

![](img/knit-publish.png){width="80%"}
